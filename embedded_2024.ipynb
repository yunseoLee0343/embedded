{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1goVNTIpnJm"
      },
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "\n",
        "import os\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/face_features_88' # change to your dataset directory\n",
        "image_paths = [os.path.join(dataset_dir, fname) for fname in os.listdir(dataset_dir) if fname.endswith('.jpg')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VsnYIQVytI7R",
        "outputId": "d02a1c33-845b-492c-be15-fb6fbc481b31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.28-py3-none-any.whl (779 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=0.2.5 (from ultralytics)\n",
            "  Downloading ultralytics_thop-0.2.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.28 ultralytics-thop-0.2.7\n"
          ]
        }
      ],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5pJEK7njtrkw",
        "outputId": "ffbcbdfe-ec71-443c-a160-868b23219e4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.7-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: protobuf, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.14 protobuf-4.25.3 sounddevice-0.4.7\n"
          ]
        }
      ],
      "source": [
        "pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTKT3L9Gq4D0"
      },
      "outputs": [],
      "source": [
        "# Extract ROI of face segment by YOLO(face detection) and OpenCV(ROI)\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "import pandas as pd\n",
        "\n",
        "data = []\n",
        "model = YOLO('yolov8n.pt')\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_NxSGMHc3G7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def extract_landmarks(rgb_image):\n",
        "    result = face_mesh.process(rgb_image)\n",
        "    if result.multi_face_landmarks:\n",
        "        print(f\"Number of faces detected: {len(result.multi_face_landmarks)}\")\n",
        "        landmarks = result.multi_face_landmarks[0]\n",
        "        return [(lm.x, lm.y, lm.z) for lm in landmarks.landmark]\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        },
        "collapsed": true,
        "id": "DJ6sYgEA-myE",
        "outputId": "0f531bca-42e8-4047-91fe-ccd3d6f0dd1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/face_features_88/face features_52.jpg', '/content/drive/MyDrive/face_features_88/humans faces_91.jpg', '/content/drive/MyDrive/face_features_88/face features_49.jpg', '/content/drive/MyDrive/face_features_88/face features_67.jpg', '/content/drive/MyDrive/face_features_88/face features_18.jpg', '/content/drive/MyDrive/face_features_88/face features_24.jpg', '/content/drive/MyDrive/face_features_88/face features_17.jpg', '/content/drive/MyDrive/face_features_88/humans faces_100.jpg', '/content/drive/MyDrive/face_features_88/face features_66.jpg', '/content/drive/MyDrive/face_features_88/face features_85.jpg', '/content/drive/MyDrive/face_features_88/humans faces_93.jpg', '/content/drive/MyDrive/face_features_88/face features_88.jpg', '/content/drive/MyDrive/face_features_88/face features_81.jpg', '/content/drive/MyDrive/face_features_88/face features_25.jpg', '/content/drive/MyDrive/face_features_88/face features_87.jpg', '/content/drive/MyDrive/face_features_88/humans faces_77.jpg', '/content/drive/MyDrive/face_features_88/humans faces_85.jpg', '/content/drive/MyDrive/face_features_88/humans faces_78.jpg', '/content/drive/MyDrive/face_features_88/humans faces_90.jpg', '/content/drive/MyDrive/face_features_88/humans faces_86.jpg', '/content/drive/MyDrive/face_features_88/humans faces_71.jpg', '/content/drive/MyDrive/face_features_88/humans faces_87.jpg', '/content/drive/MyDrive/face_features_88/humans faces_76.jpg', '/content/drive/MyDrive/face_features_88/humans faces_75.jpg', '/content/drive/MyDrive/face_features_88/humans faces_82.jpg', '/content/drive/MyDrive/face_features_88/humans faces_74.jpg', '/content/drive/MyDrive/face_features_88/humans faces_72.jpg', '/content/drive/MyDrive/face_features_88/humans faces_80.jpg', '/content/drive/MyDrive/face_features_88/humans faces_52.jpg', '/content/drive/MyDrive/face_features_88/humans faces_51.jpg', '/content/drive/MyDrive/face_features_88/humans faces_48.jpg', '/content/drive/MyDrive/face_features_88/humans faces_54.jpg', '/content/drive/MyDrive/face_features_88/humans faces_57.jpg', '/content/drive/MyDrive/face_features_88/humans faces_66.jpg', '/content/drive/MyDrive/face_features_88/humans faces_55.jpg', '/content/drive/MyDrive/face_features_88/humans faces_64.jpg', '/content/drive/MyDrive/face_features_88/humans faces_53.jpg', '/content/drive/MyDrive/face_features_88/humans faces_47.jpg', '/content/drive/MyDrive/face_features_88/humans faces_50.jpg', '/content/drive/MyDrive/face_features_88/humans faces_58.jpg', '/content/drive/MyDrive/face_features_88/humans faces_59.jpg', '/content/drive/MyDrive/face_features_88/humans faces_49.jpg', '/content/drive/MyDrive/face_features_88/humans faces_60.jpg', '/content/drive/MyDrive/face_features_88/humans faces_43.jpg', '/content/drive/MyDrive/face_features_88/humans faces_46.jpg', '/content/drive/MyDrive/face_features_88/humans faces_35.jpg', '/content/drive/MyDrive/face_features_88/humans faces_36.jpg', '/content/drive/MyDrive/face_features_88/humans faces_42.jpg', '/content/drive/MyDrive/face_features_88/humans faces_45.jpg', '/content/drive/MyDrive/face_features_88/humans faces_34.jpg', '/content/drive/MyDrive/face_features_88/humans faces_32.jpg', '/content/drive/MyDrive/face_features_88/humans faces_39.jpg', '/content/drive/MyDrive/face_features_88/humans faces_37.jpg', '/content/drive/MyDrive/face_features_88/humans faces_31.jpg', '/content/drive/MyDrive/face_features_88/humans faces_33.jpg', '/content/drive/MyDrive/face_features_88/humans faces_30.jpg', '/content/drive/MyDrive/face_features_88/humans faces_24.jpg', '/content/drive/MyDrive/face_features_88/humans faces_28.jpg', '/content/drive/MyDrive/face_features_88/humans faces_29.jpg', '/content/drive/MyDrive/face_features_88/humans faces_19.jpg', '/content/drive/MyDrive/face_features_88/humans faces_27.jpg', '/content/drive/MyDrive/face_features_88/humans faces_15.jpg', '/content/drive/MyDrive/face_features_88/humans faces_22.jpg', '/content/drive/MyDrive/face_features_88/humans faces_16.jpg', '/content/drive/MyDrive/face_features_88/humans faces_23.jpg', '/content/drive/MyDrive/face_features_88/humans faces_26.jpg', '/content/drive/MyDrive/face_features_88/humans faces_21.jpg', '/content/drive/MyDrive/face_features_88/humans faces_20.jpg', '/content/drive/MyDrive/face_features_88/humans faces_10.jpg', '/content/drive/MyDrive/face_features_88/humans faces_8.jpg', '/content/drive/MyDrive/face_features_88/humans faces_9.jpg', '/content/drive/MyDrive/face_features_88/humans faces_12.jpg', '/content/drive/MyDrive/face_features_88/humans faces_13.jpg', '/content/drive/MyDrive/face_features_88/humans faces_11.jpg']\n",
            "\n",
            "0: 480x640 1 person, 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Boxes' object has no attribute 'xmin'. See valid attributes below.\n\n    Manages detection boxes, providing easy access and manipulation of box coordinates, confidence scores, class\n    identifiers, and optional tracking IDs. Supports multiple formats for box coordinates, including both absolute and\n    normalized forms.\n\n    Attributes:\n        data (torch.Tensor): The raw tensor containing detection boxes and their associated data.\n        orig_shape (tuple): The original image size as a tuple (height, width), used for normalization.\n        is_track (bool): Indicates whether tracking IDs are included in the box data.\n\n    Properties:\n        xyxy (torch.Tensor | numpy.ndarray): Boxes in [x1, y1, x2, y2] format.\n        conf (torch.Tensor | numpy.ndarray): Confidence scores for each box.\n        cls (torch.Tensor | numpy.ndarray): Class labels for each box.\n        id (torch.Tensor | numpy.ndarray, optional): Tracking IDs for each box, if available.\n        xywh (torch.Tensor | numpy.ndarray): Boxes in [x, y, width, height] format, calculated on demand.\n        xyxyn (torch.Tensor | numpy.ndarray): Normalized [x1, y1, x2, y2] boxes, relative to `orig_shape`.\n        xywhn (torch.Tensor | numpy.ndarray): Normalized [x, y, width, height] boxes, relative to `orig_shape`.\n\n    Methods:\n        cpu(): Moves the boxes to CPU memory.\n        numpy(): Converts the boxes to a numpy array format.\n        cuda(): Moves the boxes to CUDA (GPU) memory.\n        to(device, dtype=None): Moves the boxes to the specified device.\n    ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b8d372b52b51>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# 바운딩 박스 좌표 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# ROI 추출 및 바운딩 박스 그리기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;34m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{name}' object has no attribute '{attr}'. See valid attributes below.\\n{self.__doc__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Boxes' object has no attribute 'xmin'. See valid attributes below.\n\n    Manages detection boxes, providing easy access and manipulation of box coordinates, confidence scores, class\n    identifiers, and optional tracking IDs. Supports multiple formats for box coordinates, including both absolute and\n    normalized forms.\n\n    Attributes:\n        data (torch.Tensor): The raw tensor containing detection boxes and their associated data.\n        orig_shape (tuple): The original image size as a tuple (height, width), used for normalization.\n        is_track (bool): Indicates whether tracking IDs are included in the box data.\n\n    Properties:\n        xyxy (torch.Tensor | numpy.ndarray): Boxes in [x1, y1, x2, y2] format.\n        conf (torch.Tensor | numpy.ndarray): Confidence scores for each box.\n        cls (torch.Tensor | numpy.ndarray): Class labels for each box.\n        id (torch.Tensor | numpy.ndarray, optional): Tracking IDs for each box, if available.\n        xywh (torch.Tensor | numpy.ndarray): Boxes in [x, y, width, height] format, calculated on demand.\n        xyxyn (torch.Tensor | numpy.ndarray): Normalized [x1, y1, x2, y2] boxes, relative to `orig_shape`.\n        xywhn (torch.Tensor | numpy.ndarray): Normalized [x, y, width, height] boxes, relative to `orig_shape`.\n\n    Methods:\n        cpu(): Moves the boxes to CPU memory.\n        numpy(): Converts the boxes to a numpy array format.\n        cuda(): Moves the boxes to CUDA (GPU) memory.\n        to(device, dtype=None): Moves the boxes to the specified device.\n    "
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 감지된 얼굴과 특징을 포함한 이미지를 저장할 리스트\n",
        "result_images = []\n",
        "\n",
        "for path in image_paths:\n",
        "    print(image_paths)\n",
        "    image = cv2.imread(path)  # 이미지 로드\n",
        "    if image is None:\n",
        "        print(f\"Error: Failed to load image at {path}\")\n",
        "        continue  # 이미지 로드 실패 시 다음 이미지로 넘어감\n",
        "\n",
        "    results = model(image)  # YOLO를 사용하여 얼굴 감지\n",
        "\n",
        "    # 결과 리스트에 대해 반복하여 각 이미지의 얼굴에 대한 작업 수행\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "\n",
        "        for box in boxes:\n",
        "            # 바운딩 박스 좌표 추출\n",
        "            x1, y1, x2, y2 = int(box.xmin), int(box.ymin), int(box.xmax), int(box.ymax)\n",
        "\n",
        "            # ROI 추출 및 바운딩 박스 그리기\n",
        "            roi = image[y1:y2, x1:x2]\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "\n",
        "            # box의 이름이 'face'인 경우 얼굴 랜드마크 추출\n",
        "            if box.name == 'face':\n",
        "                face_landmarks = extract_landmarks(roi)\n",
        "            # box의 이름이 'eye', 'nose', 'mouth'인 경우 특징 랜드마크 추출\n",
        "            elif box.name in ['eye', 'nose', 'mouth']:\n",
        "                feature_landmarks = extract_landmarks(roi)\n",
        "            else:\n",
        "              print(box.name)\n",
        "              if box.name == None:\n",
        "                print(\"None\")\n",
        "\n",
        "            # 데이터 저장 (선택 사항)\n",
        "            data.append({\n",
        "                'image_path': path,\n",
        "                'bounding_box': (x1, y1, x2, y2),\n",
        "                'name': box.name,\n",
        "                'landmarks': face_landmarks if box.name == 'face' else feature_landmarks\n",
        "            })\n",
        "\n",
        "    # 결과 이미지를 리스트에 추가\n",
        "    result_images.append(image)\n",
        "\n",
        "# 1, 2, 3번째 결과 이미지를 표시\n",
        "for i in range(min(3, len(result_images))):\n",
        "    cv2_imshow(result_images[i])\n",
        "\n",
        "# 작업 완료 후 모든 윈도우 닫기\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzKhMrXlCDqo"
      },
      "outputs": [],
      "source": [
        "def calculate_similarity(landmarks1, landmarks2):\n",
        "    return distance.euclidean(np.array(landmarks1), np.array(landmarks2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXTCxYJm3zbn"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}