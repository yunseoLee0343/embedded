# -*- coding: utf-8 -*-
"""final_embedded_yunseoLee0343.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WVi3IZIiHPMEhorZw_xXvIlgZeiKasYf
"""

pip install ultralytics

pip install tensorflow

pip install keras-facenet

import os
from ultralytics import YOLO

dataset_dir = '/content/drive/MyDrive/face_features_88' # change to your dataset directory
image_paths = [os.path.join(dataset_dir, fname) for fname in os.listdir(dataset_dir) if fname.endswith('.jpg')]

model = YOLO("yolov8s.pt")

import numpy as np
import tensorflow as tf

# 얼굴 탐지 함수
def detect_faces_yolo(model, image):
    results = model(image)
    if isinstance(results, list):
        detections = results[0].boxes.xyxy
    else:
        detections = results.boxes.xyxy
    return detections

# FaceNet 모델 로드 함수
def load_facenet_model(model_path):
    model = tf.keras.models.load_model(model_path)
    return model

import cv2
from google.colab.patches import cv2_imshow
from keras_facenet import FaceNet

embedder = FaceNet()
temp_paths = image_paths[:2]

# 두 개의 임베딩 벡터를 저장할 리스트
embeddings = []

for path in temp_paths:
    image = cv2.imread(path) # load image
    detections = detect_faces_yolo(model, image) # detect face using Yolo

    # Draw bounding boxes
    for detection in detections:
        x1, y1, x2, y2 = map(int, detection[:4])  # Convert coordinates to integers
        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Draw a red box

    # print("detections length: ", len(detections))

    # 바운딩 박스 그리기 및 임베딩 추출
    for detection in detections:
        x1, y1, x2, y2 = map(int, detection[:4])  # 좌표를 정수로 변환
        face = image[y1:y2, x1:x2]  # 얼굴 영역 추출

        # FaceNet 모델을 사용하여 얼굴 임베딩 추출
        embedding = embedder.extract(face, threshold=0.95)  # 얼굴 영역만을 입력으로 사용
        embeddings.append(embedding[0]['embedding'])  # 임베딩 벡터 저장
        print(f'Face embedding for detection {detection}: {embedding}')

        # 이미지에 바운딩 박스 그리기
        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)  # 빨간색 박스

    # Display the image
    cv2_imshow(image)

    print(detections) # Print the detected bounding boxes

import cv2
from google.colab.patches import cv2_imshow
from keras_facenet import FaceNet

embedder = FaceNet()
temp_paths = image_paths[:2]

# 두 개의 임베딩 벡터를 저장할 리스트
embeddings = []

for path in temp_paths:
    image = cv2.imread(path)  # 이미지 로드
    detections = detect_faces_yolo(model, image)  # YOLO를 사용하여 얼굴 탐지

    # 바운딩 박스 그리기
    for detection in detections:
        x1, y1, x2, y2 = map(int, detection[:4])  # 좌표를 정수로 변환
        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)  # 빨간색 박스 그리기

    # 얼굴 영역 추출
    face = image[y1:y2, x1:x2]  # 얼굴 영역 추출

    # FaceNet 모델을 사용하여 얼굴 임베딩 추출
    embedding = embedder.extract(face, threshold=0.95)[0]['embedding']  # 얼굴 영역만을 입력으로 사용하여 임베딩 추출
    embeddings.append(embedding)  # 임베딩 벡터 저장
    print(f'Face embedding for detection {detection}: {embedding}')

    # 이미지 출력
    cv2_imshow(image)

    print(detections)  # 탐지된 바운딩 박스 출력

# 두 이미지의 임베딩 벡터 출력
print("Embeddings for the first image:", embeddings[0])
print("Embeddings for the second image:", embeddings[1])

import numpy as np
from scipy.spatial.distance import euclidean, cosine

# 유사도 계산 함수
def calculate_similarity(embedding1, embedding2, metric='euclidean'):
    if metric == 'euclidean':
        return euclidean(embedding1, embedding2)
    elif metric == 'cosine':
        return cosine(embedding1, embedding2)
    else:
        raise ValueError("지원하지 않는 유사도 측정 방식입니다. 'euclidean' 또는 'cosine'을 사용하세요.")

# 두 개의 임베딩 벡터 간의 유사도 계산
if len(embeddings) == 2:
    embedding1, embedding2 = embeddings
    euclidean_distance = calculate_similarity(embedding1, embedding2, metric='euclidean')
    cosine_similarity = calculate_similarity(embedding1, embedding2, metric='cosine')

    print(f'유클리드 거리: {euclidean_distance}')
    print(f'코사인 유사도: {cosine_similarity}')
else:
    print("임베딩 벡터의 수가 정확하지 않습니다. 두 개의 임베딩 벡터가 필요합니다.")